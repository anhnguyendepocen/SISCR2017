---
title: "Module 2: Bayesian Methods for Clinical Research - Introduction"
date: "July 24, 2017"
author: "Rebecca Hubbard, Lurdes Inoue"
output:
  html_document:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  

***


### Install R
- Go to http://cran.rstudio.com/
- Click on the "Download R for [operating system]" link that is appropriate for your operating system and follow the instructions.
- Open R and make sure it works (i.e. that no error messages come up)


### Install RStudio
- Go to http://www.rstudio.com/products/rstudio/download/
- Select the installer that is appropriate for your operating system under "Installers for Supported Platforms" and follow the instructions.
- Open RStudio and make sure it works.

### Install R Packages
- For this module we will be using the _LearnBayes_ and _arm_ packages
- To use these packages you first need to install them using _install.packages()_
```{r, eval=FALSE}
install.packages("LearnBayes")
install.packages("arm")
```
- You then need to load these libraries: 
```{r, eval=FALSE}
library(LearnBayes)
library(arm)
```
```{r, eval=TRUE, echo = FALSE, message = FALSE}
library(LearnBayes)
library(arm)
```

- After the first time you install the packages on your computer, you will only need to load the libraries in the future 

***

### Introduction to Bayesian Computing

#### Discrete prior for a continuous parameter

1. You are conducting a trial of a new treatment for thyroid cancer and have obtained results for the first 80 patients.63 patients 
responded to treatment and 17 patients did not. We now want to obtain the posterior distribution for the probability of responding
to this new treatment. Use R to generate the posterior distribution and compute the posterior median under the following priors:

    a. Flat prior on [0,1]
    
    ```{r, eval = TRUE}
#-- prior values for probability of response
theta <- seq(0,1,length.out=99)

#-- likelihood times prior
prior <- rep(1/99, 99)
product <- dbinom(x=63, size=80, prob=theta)*prior

#-- posterior is the normalized likelihood times prior
posterior <- product/sum(product)

#-- plot posterior distribution
plot(theta, posterior, type='h', xlab=expression(~theta))

#-- posterior mean
mean.post <- sum(theta*posterior)

#-- cumulative posterior distribution
cumulative.post <- cumsum(posterior)

#-- median (approximate)
median.post <- theta[max(which(cumulative.post <=0.50))]
```

    b. Flat prior on [0.8,1]
    
    ```{r, eval = TRUE}
#-- prior values for probability of response
theta <- seq(0.8,1,length.out=99)

#-- likelihood times prior
prior <- rep(1/99, 99)
product <- dbinom(x=63, size=80, prob=theta)*prior

#-- posterior is the normalized likelihood times prior
posterior <- product/sum(product)

#-- plot posterior distribution
plot(theta, posterior, type='h', xlab=expression(~theta))

#-- posterior mean
mean.post <- sum(theta*posterior)

#-- cumulative posterior distribution
cumulative.post <- cumsum(posterior)

#-- median (approximate)
median.post <- theta[max(which(cumulative.post <=0.50))]
```    

What is the danger of using the prior in (b)?    
    
2. Let's analyze the same set of results using _LearnBayes_. 

    a. Flat prior on [0,1]
    
    ```{r, eval = TRUE}
triplot(prior=c(1,1),data=c(63,17), where = "topleft")
```
    
    b. Beta(4,4) prior
    
    ```{r, eval = TRUE}
triplot(prior=c(4,4),data=c(63,17), where = "topleft")
```

3. Now suppose we want to test the hypothesis that the probability of response to our new treatment is 0.8. Assuming we have equipoise
regarding this hypothesis (i.e., we think it is equally likely to be true or false) and that our alternative hypothesis is that the
response probability is equally likely to take any value from 0 to 1, what are the posterior probability of the null hypothesis and
the Bayes Factor? Is there evidence for or against our null hypothesis?

    ```{r, eval = TRUE}
pbetat(p0=0.8, prob=0.5, ab=c(1,1), data=c(63,17))
```

4. Finally, what if we want to estimate the posterior predictive distribution of response for a new patient based on the data that we have observed and assuming that we initially 
had a Beta(4,4) prior for the probability of response. (Recall that by using a conjugate prior our posterior distribution is also Beta with parameters $a+y-1$ and $b+n-y-1$.)

    ```{r, eval = TRUE}
pbetap(ab=c((4+63-1),(4+17-1)), n=1, s=0:1)
```

***

### Bayesian Regression Models

In this lab, we will conduct an analysis using a Bayesian logistic regression model. Data come from a cross-sectional study of 1,225 smokers over the age of 40. Each participant was assessed for chronic obstructive pulmonary disease (COPD), and characteristics of the type of cigarette they most frequently smoke were recorded. The objective of the study was to identify associations between COPD diagnosis and cigarette characteristics.

We will use the following variables form this data set:

- TYPE: Type of cigarette, 1 = Menthol, 0 = Regular

- NIC: Nicotine content, in mg

- TAR: Tar content, in mg

- LEN: Length of cigarette, in mm

- FLTR: 1 = Filter, 0 = No filter

- copd: 1 = COPD diagnosis, 0 = no COPD diagnosis


You can download the data file and read it into R as follows:
```{r, eval = TRUE}
copd <- read.csv("https://raw.githubusercontent.com/rhubb/SISCR2017/master/data/copd.csv", header = T)
```

1. First carry out some exploratory data analysis to summarize the distribution of copd, cigarette type, nicotine content, and filter.

    ```{r, eval = TRUE}
#-- univariate tables for categorical variables
table(copd$copd)/sum(table(copd$copd))  
table(copd$TYPE)/sum(table(copd$TYPE))
table(copd$FLTR)/sum(table(copd$FLTR))

##-- bivariate tables for categorical predictors and copd
table(copd$TYPE,copd$copd)
t(sweep(table(copd$copd,copd$TYPE),2,rowSums(table(copd$TYPE,copd$copd)),"/"))
table(copd$FLTR,copd$copd)
t(sweep(table(copd$copd,copd$FLTR),2,rowSums(table(copd$FLTR,copd$copd)),"/"))

##-- summary statistics for nicotine content by copd
by(copd$NIC,copd$copd,mean)
by(copd$NIC,copd$copd,sd)
boxplot(copd$NIC ~ copd$copd, xlab = "COPD", ylab = "Nicotine (mg)")
    ```

2. Next, use Bayesian logistic regression to analyze the association between COPD and predictors cigarette type, nicotine content, and filter. We will explore results using severaly prior distributions. For each prior distribution can you think of a context in which this prior would be preferred? Compare your results to a standard frequentist logistic regression. How does the interpretation of the results differ for the Bayesian GLM compared to the frequentist GLM?

  a. Normal(0,10) prior 

    ```{r, eval = TRUE}
## -- Normal priors for regression coefficients (with mean=0 and scale=10)
copd.n10 <- bayesglm(copd ~ TYPE + NIC + FLTR, data=copd, family=binomial, prior.mean=0, 
   prior.scale=10, prior.df=Inf)
display(copd.n10)
    ```
  
  b. Normal(0,0.1) prior

    ```{r, eval = TRUE}
## -- Normal priors for regression coefficients (with mean=0 and scale=0.1)
copd.n1 <- bayesglm(copd ~ TYPE + NIC + FLTR, data=copd, family=binomial, prior.mean=0, 
   prior.scale=0.1, prior.df=Inf)
display(copd.n1)
    ```

  c. Cauchy prior

    ```{r, eval = TRUE}
## -- Cauchy priors for regression coefficients 
copd.cau <- bayesglm(copd ~ TYPE + NIC + FLTR, data=copd, family=binomial, prior.mean=0, 
   prior.scale=10)
display(copd.cau)
    ```
  d. Frequentist logistic regression

    ```{r, eval = TRUE}
copd.glm1 <- glm(copd ~ TYPE + NIC + FLTR, data=copd, family=binomial)
display(copd.glm1)
    ```
    
3. Using one of the models you fit in (2) interpret your results.     

4. How would the results in (2) differ if we had used a smaller data set? Refit the models in (2) using only the first 200 observations in the data set. What can you say about the results for cigarette type?

  a. Normal(0,10) prior 

    ```{r, eval = TRUE}
## -- Normal priors for regression coefficients (with mean=0 and scale=10)
copd.n10.v2 <- bayesglm(copd ~ TYPE + NIC + FLTR, data=copd[1:200,], family=binomial, prior.mean=0, 
   prior.scale=10, prior.df=Inf)
display(copd.n10.v2)
    ```
  
  b. Normal(0,0.1) prior

    ```{r, eval = TRUE}
## -- Normal priors for regression coefficients (with mean=0 and scale=0.1)
copd.n1.v2 <- bayesglm(copd ~ TYPE + NIC + FLTR, data=copd[1:200,], family=binomial, prior.mean=0, 
   prior.scale=0.1, prior.df=Inf)
display(copd.n1.v2)
    ```

  c. Cauchy prior

    ```{r, eval = TRUE}
## -- Cauchy priors for regression coefficients 
copd.cau.v2 <- bayesglm(copd ~ TYPE + NIC + FLTR, data=copd[1:200,], family=binomial, prior.mean=0, 
   prior.scale=10)
display(copd.cau.v2)
    ```
  d. Frequentist logistic regression

    ```{r, eval = TRUE}
copd.glm1.v2 <- glm(copd ~ TYPE + NIC + FLTR, data=copd[1:200,], family=binomial)
display(copd.glm1.v2)
    ```
  