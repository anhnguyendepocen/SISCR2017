---
title: "Module 2: Bayesian Methods for Clinical Research - Introduction"
date: "July 24, 2017"
author: "Rebecca Hubbard, Lurdes Inoue"
output:
  html_document:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  

***


### Install R
- Go to http://cran.rstudio.com/
- Click on the "Download R for [operating system]" link that is appropriate for your operating system and follow the instructions.
- Open R and make sure it works (i.e. that no error messages come up)


### Install RStudio
- Go to http://www.rstudio.com/products/rstudio/download/
- Select the installer that is appropriate for your operating system under "Installers for Supported Platforms" and follow the instructions.
- Open RStudio and make sure it works.

### Install R Packages
- For this module we will be using the _LearnBayes_ and _arm_ packages
- To use these packages you first need to install them using _install.packages()_
```{r, eval=FALSE}
install.packages("LearnBayes")
install.packages("arm")
```
- You then need to load these libraries: 
```{r, eval=TRUE}
library(LearnBayes)
library(arm)
```
- After the first time you install the packages on your computer, you will only need to load the libraries in the future 

***

### Introduction to Bayesian Computing with Learn Bayes

#### Discrete prior for a continuous parameter

1. You are conducting a trial of a new treatment for thyroid cancer and have obtained results for the first 80 patients.63 patients 
responded to treatment and 17 patients did not. We now want to obtain the posterior distribution for the probability of responding
to this new treatment. Use R to generate the posterior distribution and compute the posterior median under the following priors:

    a. Flat prior on [0,1]
    
```{r, eval = TRUE}
#-- prior values for probability of response
theta <- seq(0,1,length.out=99)

#-- likelihood times prior
prior <- rep(1/99, 99)
product <- dbinom(x=63, size=80, prob=theta)*prior

#-- posterior is the normalized likelihood times prior
posterior <- product/sum(product)

#-- plot posterior distribution
plot(theta, posterior, type='h', xlab=expression(~theta))

#-- posterior mean
mean.post <- sum(theta*posterior)

#-- cumulative posterior distribution
cumulative.post <- cumsum(posterior)

#-- median (approximate)
median.post <- theta[max(which(cumulative.post <=0.50))]
```

    b. Flat prior on [0.8,1]
    
```{r, eval = TRUE}
#-- prior values for probability of response
theta <- seq(0.8,1,length.out=99)

#-- likelihood times prior
prior <- rep(1/99, 99)
product <- dbinom(x=63, size=80, prob=theta)*prior

#-- posterior is the normalized likelihood times prior
posterior <- product/sum(product)

#-- plot posterior distribution
plot(theta, posterior, type='h', xlab=expression(~theta))

#-- posterior mean
mean.post <- sum(theta*posterior)

#-- cumulative posterior distribution
cumulative.post <- cumsum(posterior)

#-- median (approximate)
median.post <- theta[max(which(cumulative.post <=0.50))]
```    

What is the danger of using the prior in (b)?    
    
2. Let's analyze the same set of results using _LearnBayes_. 

    a. Flat prior on [0,1]
    
```{r, eval = TRUE}
triplot(prior=c(1,1),data=c(63,17), where = "topleft")

```
    b. Beta(4,4) prior
    
```{r, eval = TRUE}
triplot(prior=c(4,4),data=c(63,17), where = "topleft")
```

3. Now suppos we want to test the hypothesis that the probability of response to our new treatment is 0.8. Assuming we have equipoise
regarding this hypothesis (i.e., we think it is equally likely to be true or false) and that our alternative hypothesis is that the
response probability is equally likely to take any value from 0 to 1, what are the posterior probability of the null hypothesis and
the Bayes Factor? Is there evidence for or against our null hypothesis?

```{r, eval = TRUE}
pbetat(p0=0.8, prob=0.5, ab=c(1,1), data=c(63,17))
```